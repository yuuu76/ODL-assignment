{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPM3vfQb0oBkR4I/ZeUlg2l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuuu76/ODL-assignment/blob/main/DNN(WQ).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "24YKTkX4yqgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777f8a19-0b28-455d-c83b-4f446875e035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded all libraries\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET # for parsing XML\n",
        "from PIL import Image # to read images\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import load_img\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation\n",
        "\n",
        "print(\"Loaded all libraries\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuuTK__p3vWJ",
        "outputId": "b0e1c4ce-cebb-4f0a-f96f-2724dce03ebc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for label\n",
        "all_images = os.listdir('/content/drive/MyDrive/ODLAssignment/cropped_images')\n",
        "# for cropped and resized image\n",
        "file_path = '/content/drive/MyDrive/ODLAssignment/resized_images_array.npy'\n",
        "resized_images_array = np.load(file_path)\n",
        "\n",
        "# Extract breed and dog information from filenames\n",
        "breed_dog_info = [img.split('_') for img in all_images]\n",
        "\n",
        "# Join the parts to get the full breed name\n",
        "breeds = ['_'.join(parts) for parts in breed_dog_info]\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "resized_images_array = np.array(resized_images_array)\n",
        "breeds = np.array(breeds)\n",
        "\n",
        "# Print the length of the arrays\n",
        "print(f\"Number of images: {len(resized_images_array)}\")\n",
        "print(f\"Number of breeds: {len(breeds)}\")\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(resized_images_array, breeds, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shape of the resulting arrays\n",
        "print(f\"Shape of train_images: {train_images.shape}\")\n",
        "print(f\"Shape of test_images: {test_images.shape}\")\n",
        "print(f\"Shape of train_labels: {train_labels.shape}\")\n",
        "print(f\"Shape of test_labels: {test_labels.shape}\")"
      ],
      "metadata": {
        "id": "O8cetw364BMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0022fe8b-0935-4c92-d4ef-1bf45ab1d19e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 20580\n",
            "Number of breeds: 20580\n",
            "Shape of train_images: (16464, 250, 250, 3)\n",
            "Shape of test_images: (4116, 250, 250, 3)\n",
            "Shape of train_labels: (16464,)\n",
            "Shape of test_labels: (4116,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images_normalized = train_images / 255.0\n",
        "test_images_normalized = test_images / 255.0\n"
      ],
      "metadata": {
        "id": "NY8lsisA9M-R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_path = '/content/drive/MyDrive/ODLAssignment/dnn_model.h5'\n",
        "loaded_model = load_model(model_path)"
      ],
      "metadata": {
        "id": "E0cNrOYEELlm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## models"
      ],
      "metadata": {
        "id": "nZplkyM1H5vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(250, 250, 3)))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9oBKb6BmCzMy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/ODLAssignment/dnn_model.h5'\n",
        "\n",
        "# Save the model\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JP5ttUQD4pE",
        "outputId": "65e75e8e-240b-4af3-f7a6-1af27d21d580"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(250, 250, 3)),  # Assuming images are resized to 250x250 pixels\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(np.unique(train_labels)), activation='softmax')  # Output layer with softmax activation for classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "su6WkC5s3vUI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with batch processing\n",
        "batch_size = 16\n",
        "history = loaded_model.fit(train_images_normalized, train_labels, epochs=10, validation_split=0.2, batch_size=batch_size, verbose = 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "cqQ3n0rJ3cPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images_normalized, test_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Display training history (optional)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sZVL1sr63u8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHJ9EJr73uvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}